# Resultados del An√°lisis de Predicci√≥n de Supervivencia de Pacientes con Cirrosis

## üîç Resumen Ejecutivo

Este documento presenta los resultados completos del an√°lisis de machine learning para predecir la supervivencia de pacientes con cirrosis. El proyecto transform√≥ un problema de clasificaci√≥n multiclase en binario (Sobrevive/No sobrevive) y evalu√≥ 6 modelos diferentes con t√©cnicas avanzadas de preprocesamiento y reducci√≥n de dimensionalidad.

### üìä Resultados Principales

- **Mejor modelo**: XGBoost con **F1-Score: 0.7059** y **AUC: 0.7541** en test
- **Dataset procesado**: 418 pacientes, 775 caracter√≠sticas despu√©s de codificaci√≥n
- **T√©cnicas aplicadas**: SMOTE para balanceo, StandardScaler para normalizaci√≥n, PCA para reducci√≥n
- **Reducci√≥n dimensional**: 70.5% de reducci√≥n (775 ‚Üí 229 caracter√≠sticas) manteniendo 95% de varianza

---

## üìã 1. Informaci√≥n General del Dataset

### Caracter√≠sticas del Dataset

- **Tama√±o**: 418 pacientes con 17 caracter√≠sticas originales
- **Variable objetivo original**: 3 clases (C: Censurado, CL: Trasplante, D: Muerte)
- **Variable objetivo transformada**: 2 clases (Sobrevive: 232 pacientes, No sobrevive: 186 pacientes)
- **Distribuci√≥n final**: 55.5% Sobrevive vs 44.5% No sobrevive

### Tipos de Variables

- **Variables categ√≥ricas (10)**: Drug, Sex, Ascites, Hepatomegaly, Spiders, Edema, Cholesterol, Copper, Tryglicerides, Platelets
- **Variables num√©ricas (7)**: Age, Bilirubin, Albumin, Alk_Phos, SGOT, Prothrombin, Stage

### An√°lisis de Valores Faltantes

| Variable      | Valores Faltantes | Porcentaje |
| ------------- | ----------------- | ---------- |
| Cholesterol   | 106               | 25.36%     |
| Copper        | 106               | 25.36%     |
| Tryglicerides | 106               | 25.36%     |
| SGOT          | 106               | 25.36%     |
| Alk_Phos      | 106               | 25.36%     |
| Drug          | 105               | 25.12%     |
| Platelets     | 7                 | 1.67%      |
| Stage         | 6                 | 1.44%      |
| Prothrombin   | 2                 | 0.48%      |

---

## ‚öôÔ∏è 2. Preprocesamiento de Datos

### 2.1 Estrategia de Imputaci√≥n

- **Variables num√©ricas**: Imputaci√≥n con mediana
- **Variables categ√≥ricas**: Imputaci√≥n con moda (valor m√°s frecuente)
- **Resultado**: 0 valores faltantes despu√©s del preprocesamiento

### 2.2 Codificaci√≥n de Variables

- **Variables binarias**: LabelEncoder (ej: Sex)
- **Variables multicateg√≥ricas**: OneHot Encoding
- **Dimensiones finales**: 775 caracter√≠sticas despu√©s de codificaci√≥n
- **Variable objetivo**: LabelEncoder (0 = No_sobrevive, 1 = Sobrevive)

### 2.3 Divisi√≥n de Datos

- **Entrenamiento**: 292 muestras (69.9%)
- **Validaci√≥n**: 63 muestras (15.1%)
- **Test**: 63 muestras (15.1%)

### 2.4 Normalizaci√≥n y Balanceo

- **M√©todo de normalizaci√≥n**: StandardScaler
- **T√©cnica de balanceo**: SMOTE (Synthetic Minority Oversampling Technique)
- **Efecto de SMOTE**: 292 ‚Üí 324 muestras (130‚Üí162 cada clase)

---

## ü§ñ 3. Configuraci√≥n de Modelos

Se evaluaron 6 modelos diferentes con Grid Search para optimizaci√≥n de hiperpar√°metros:

### 3.1 Modelos Evaluados

| Modelo                  | Tipo                | Combinaciones | Tiempo (seg) |
| ----------------------- | ------------------- | ------------- | ------------ |
| **Regresi√≥n Log√≠stica** | Param√©trico         | 3             | 3.66         |
| **K-Nearest Neighbors** | No param√©trico      | 16            | 2.32         |
| **Random Forest**       | Ensamble de √°rboles | 24            | 6.26         |
| **XGBoost**             | Gradient Boosting   | 48            | 22.49        |
| **MLP (Red Neuronal)**  | Red neuronal        | 4             | 8.83         |
| **SVM**                 | M√°quina de vectores | 6             | 1.73         |

### 3.2 Mejores Hiperpar√°metros por Modelo

**Random Forest** (Mejor en validaci√≥n):

- n_estimators: 200
- max_depth: 20
- max_features: 'sqrt'
- min_samples_split: 5

**XGBoost** (Mejor en test):

- n_estimators: 100
- max_depth: 4
- learning_rate: 0.1
- subsample: 1.0
- colsample_bytree: 1.0

---

## üìà 4. Resultados de Entrenamiento y Validaci√≥n

### 4.0 Justificaci√≥n de M√©tricas de Evaluaci√≥n

Para este problema, la selecci√≥n de m√©tricas es crucial para una evaluaci√≥n realista del rendimiento del modelo en un contexto cl√≠nico:

- **F1-Score**: Es la m√©trica principal para la optimizaci√≥n, ya que busca el mejor balance entre **Precisi√≥n** (evitar falsos positivos) y **Recall/Sensibilidad** (detectar todos los casos positivos). En medicina, es vital no solo identificar correctamente a los pacientes que no sobrevivir√°n (recall), sino tambi√©n evitar alarmar innecesariamente a los que s√≠ lo har√°n (precisi√≥n).
- **AUC-ROC**: Mide la capacidad del modelo para distinguir entre las clases (Sobrevive vs. No sobrevive). Un valor alto indica que el modelo es bueno para clasificar correctamente a los pacientes.
- **Specificity**: Mide la capacidad de identificar correctamente a los pacientes que sobreviven (verdaderos negativos). Es el complemento del recall.
- **Accuracy**: Aunque √∫til, puede ser enga√±osa si las clases est√°n desbalanceadas. Se incluye como una medida de rendimiento general.

**Importante**: Aunque se us√≥ SMOTE para balancear los datos de _entrenamiento_, la evaluaci√≥n se realiza en los conjuntos de _validaci√≥n y test originales (no balanceados)_ para simular un escenario real.

### 4.1 M√©tricas en Conjunto de Validaci√≥n

| Modelo                  | Accuracy   | Precision  | Recall     | Specificity | F1-Score   | AUC-ROC    |
| ----------------------- | ---------- | ---------- | ---------- | ----------- | ---------- | ---------- |
| **Random Forest**       | **0.7937** | **0.7895** | **0.8571** | **0.7143**  | **0.8219** | **0.8714** |
| **XGBoost**             | 0.6984     | 0.7105     | 0.7714     | 0.6071      | 0.7397     | 0.7898     |
| **SVM**                 | 0.6667     | 0.6667     | 0.8000     | 0.5000      | 0.7273     | 0.7378     |
| **Regresi√≥n Log√≠stica** | 0.6349     | 0.6500     | 0.7429     | 0.5000      | 0.6933     | 0.7245     |
| **MLP**                 | 0.6190     | 0.6410     | 0.7143     | 0.5000      | 0.6757     | 0.6459     |
| **KNN**                 | 0.4603     | 0.6000     | 0.0857     | 0.9286      | 0.1500     | 0.6388     |

### 4.2 Interpretaci√≥n de Resultados en Validaci√≥n

**üèÜ Random Forest** demostr√≥ el mejor rendimiento general:

- **F1-Score m√°s alto**: 0.8219 indica excelente balance entre precisi√≥n y recall
- **Recall alto**: 0.8571 significa que detecta correctamente el 85.7% de supervivientes
- **AUC-ROC excepcional**: 0.8714 indica muy buena capacidad discriminativa

**‚ö†Ô∏è KNN** mostr√≥ el peor rendimiento:

- **Recall muy bajo**: 0.0857 indica que solo detecta 8.6% de supervivientes
- **F1-Score bajo**: 0.1500 debido al pobre recall, a pesar de alta especificidad

---

## üéØ 5. Evaluaci√≥n Final en Conjunto de Test

### 5.1 M√©tricas en Conjunto de Test

| Modelo                  | Accuracy   | Precision  | Recall     | Specificity | F1-Score   | AUC-ROC    |
| ----------------------- | ---------- | ---------- | ---------- | ----------- | ---------- | ---------- |
| **XGBoost**             | **0.6825** | **0.7273** | **0.6857** | **0.6786**  | **0.7059** | **0.7541** |
| **SVM**                 | 0.6667     | 0.7059     | 0.6857     | 0.6429      | 0.6957     | 0.7112     |
| **Regresi√≥n Log√≠stica** | 0.6667     | 0.7188     | 0.6571     | 0.6786      | 0.6866     | 0.7143     |
| **MLP**                 | 0.6667     | 0.7500     | 0.6000     | 0.7500      | 0.6667     | 0.7418     |
| **Random Forest**       | 0.6349     | 0.6875     | 0.6286     | 0.6429      | 0.6567     | 0.7255     |
| **KNN**                 | 0.4921     | 1.0000     | 0.0857     | 1.0000      | 0.1579     | 0.6913     |

### 5.2 Interpretaci√≥n de Resultados en Test

**üèÜ XGBoost** emergi√≥ como el mejor modelo en test:

- **Mejor F1-Score**: 0.7059 con buen balance entre m√©tricas
- **AUC-ROC s√≥lido**: 0.7541 indica buena capacidad predictiva
- **Balance √≥ptimo**: Mejores m√©tricas generales comparado con otros modelos

**üìâ Diferencia validaci√≥n vs test**:

- Random Forest baj√≥ de 0.8219 a 0.6567 en F1-Score (posible sobreajuste)
- XGBoost se mantuvo m√°s estable: 0.7397 ‚Üí 0.7059

---

## üî¨ 6. An√°lisis de Caracter√≠sticas

### 6.1 Caracter√≠sticas con Mayor Capacidad Discriminativa (Mutual Information)

| Ranking | Caracter√≠stica        | MI Score | Interpretaci√≥n                                             |
| ------- | --------------------- | -------- | ---------------------------------------------------------- |
| 1       | **Bilirubin**         | 0.2022   | Nivel de bilirrubina (indicador clave de funci√≥n hep√°tica) |
| 2       | **Copper_68**         | 0.1034   | Nivel espec√≠fico de cobre en sangre                        |
| 3       | **Cholesterol_194**   | 0.0925   | Nivel espec√≠fico de colesterol                             |
| 4       | **Platelets_124**     | 0.0841   | Conteo espec√≠fico de plaquetas                             |
| 5       | **Tryglicerides_108** | 0.0839   | Nivel espec√≠fico de triglic√©ridos                          |

### 6.2 An√°lisis de Correlaciones

- **249 pares de variables** con correlaci√≥n alta (|r| > 0.8)
- **501 caracter√≠sticas** con baja capacidad discriminativa (MI < 0.01)
- **186 caracter√≠sticas redundantes** identificadas para posible eliminaci√≥n

### 6.3 Implicaciones Cl√≠nicas

- **Bilirubin** como predictor m√°s importante confirma su relevancia cl√≠nica en cirrosis
- **Niveles espec√≠ficos** de laboratorio muestran m√°s poder predictivo que rangos generales
- **Alta dimensionalidad** sugiere la necesidad de t√©cnicas de reducci√≥n

---

## üìâ 7. Reducci√≥n de Dimensionalidad con PCA

### 7.1 Configuraci√≥n de PCA

- **Criterio**: Mantener 95% de la varianza explicada
- **Componentes seleccionados**: 229 de 775 (reducci√≥n del 70.5%)
- **Varianza conservada**: 95.0%

### 7.2 Resultados con PCA

| Modelo            | M√©todo   | F1-Val | F1-Test | Acc-Test | Dimensiones | Reducci√≥n |
| ----------------- | -------- | ------ | ------- | -------- | ----------- | --------- |
| **Random Forest** | Original | 0.8219 | 0.6567  | 0.6349   | 775         | 0.0%      |
| **Random Forest** | PCA      | 0.7606 | 0.6027  | 0.5397   | 229         | 70.5%     |
| **XGBoost**       | Original | 0.7397 | 0.7059  | 0.6825   | 775         | 0.0%      |
| **XGBoost**       | PCA      | 0.7778 | 0.5882  | 0.5556   | 229         | 70.5%     |

### 7.3 An√°lisis del Impacto de PCA

**üìä Cambios en F1-Score (Test)**:

- **Random Forest**: 0.6567 ‚Üí 0.6027 (-8.2%)
- **XGBoost**: 0.7059 ‚Üí 0.5882 (-16.7%)

**üîç Interpretaci√≥n**:

- PCA logra reducci√≥n significativa de dimensionalidad
- **Trade-off performance vs simplicidad**: P√©rdida moderada de rendimiento por gran simplificaci√≥n
- **XGBoost m√°s sensible** a la reducci√≥n dimensional que Random Forest

---

## üìã 8. Resumen Final y Recomendaciones

### 8.0 Tabla Comparativa Completa

La siguiente tabla consolida los resultados de todos los modelos, tanto en su versi√≥n original como con la reducci√≥n de dimensionalidad PCA, ordenados por rendimiento en el conjunto de test para una f√°cil comparaci√≥n.

| Modelo                  | M√©todo   | F1 (Validaci√≥n) | F1 (Test)  | AUC (Test) | Dimensiones | Reducci√≥n |
| ----------------------- | -------- | --------------- | ---------- | ---------- | ----------- | --------- |
| **XGBoost**             | Original | 0.7397          | **0.7059** | **0.7541** | 775         | 0.0%      |
| **SVM**                 | Original | 0.7273          | 0.6957     | 0.7112     | 775         | 0.0%      |
| **Regresi√≥n Log√≠stica** | Original | 0.6933          | 0.6866     | 0.7143     | 775         | 0.0%      |
| **MLP**                 | Original | 0.6757          | 0.6667     | 0.7418     | 775         | 0.0%      |
| **Random Forest**       | Original | 0.8219          | 0.6567     | 0.7255     | 775         | 0.0%      |
| Random Forest           | PCA      | 0.7606          | 0.6027     | 0.6204     | 229         | 70.5%     |
| XGBoost                 | PCA      | 0.7778          | 0.5882     | 0.6612     | 229         | 70.5%     |
| **KNN**                 | Original | 0.1500          | 0.1579     | 0.6913     | 775         | 0.0%      |

### 8.1 Modelo Recomendado

**üèÜ XGBoost (Configuraci√≥n Original)**

- **F1-Score**: 0.7059
- **AUC-ROC**: 0.7541
- **Caracter√≠sticas**: 775
- **Ventajas**: Mejor rendimiento general, estabilidad entre validaci√≥n y test

### 8.2 Hallazgos Clave

1. **Transformaci√≥n exitosa**: Conversi√≥n de problema multiclase a binario mejor√≥ interpretabilidad
2. **SMOTE efectivo**: Balanceo de clases mejor√≥ entrenamiento sin comprometer evaluaci√≥n realista
3. **Ensambles superiores**: Random Forest y XGBoost consistentemente superaron otros modelos
4. **Bilirubin como predictor clave**: Confirmaci√≥n de relevancia cl√≠nica conocida
5. **PCA viable con trade-offs**: 70.5% reducci√≥n dimensional con p√©rdida aceptable de rendimiento

### 8.3 Consideraciones Cl√≠nicas

**‚úÖ Fortalezas del Modelo**:

- F1-Score > 0.7 indica buen balance para decisiones m√©dicas
- AUC > 0.75 sugiere capacidad discriminativa cl√≠nicamente √∫til
- Uso de caracter√≠sticas interpretables (laboratorio est√°ndar)

**‚ö†Ô∏è Limitaciones**:

- Dataset relativamente peque√±o (418 pacientes)
- Posible sobreajuste en algunos modelos (Random Forest)
- Necesidad de validaci√≥n externa en poblaciones diferentes

### 8.4 Recomendaciones para Implementaci√≥n

1. **Modelo de producci√≥n**: XGBoost con configuraci√≥n optimizada
2. **Monitoreo continuo**: Evaluaci√≥n regular en nuevos datos
3. **Interpretabilidad**: Implementar SHAP values para explicaciones por paciente
4. **Validaci√≥n externa**: Probar en diferentes hospitales/poblaciones
5. **Actualizaci√≥n peri√≥dica**: Re-entrenamiento con nuevos datos cl√≠nicos

---

## üìä 9. M√©tricas T√©cnicas Detalladas

### 9.1 Configuraci√≥n Experimental

- **Validaci√≥n cruzada**: Stratified 5-Fold
- **M√©trica de optimizaci√≥n**: F1-Score
- **Procesadores utilizados**: Paralelizaci√≥n completa (-1)
- **Semillas aleatorias**: 42 (reproducibilidad garantizada)

### 9.2 Tiempo de Ejecuci√≥n

- **Tiempo total**: ~45 segundos
- **Modelo m√°s r√°pido**: KNN (2.32s)
- **Modelo m√°s lento**: XGBoost (22.49s)
- **Eficiencia**: Excelente relaci√≥n tiempo/rendimiento

### 9.3 Estabilidad de Resultados

- **Validaci√≥n cruzada consistente**: Baja varianza entre folds
- **Reproducibilidad**: Resultados id√©nticos con misma semilla
- **Robustez**: Modelos estables ante peque√±as variaciones en datos

---

_An√°lisis completado el [fecha] con Python 3.x, scikit-learn, XGBoost y librer√≠as asociadas._
